{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C S 363D HW 10\n",
    "\n",
    "# Hierarchical Clustering and Cluster Evaluation\n",
    "\n",
    "## Ana Williams and Fronrich Puno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib, json, requests, re\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('blanton_list.xlsx', \n",
    "                   dtype={i:object for i in range(0,10)})\n",
    "df = df[df['Accession #'] != 2016.207]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual fixes\n",
    "#2016.1 fix\n",
    "df.at[292,'Accession #'] = '2016.100'\n",
    "df.at[332,'Accession #'] = '2016.10'\n",
    "df.at[829,'Accession #'] = '2016.1'\n",
    "#2014.1 fixes \n",
    "df.at[688,'Accession #'] = '2014.100'\n",
    "df.at[803,'Accession #'] = '2014.1'\n",
    "#1999.1 fixes\n",
    "df.at[673,'Accession #'] = '1999.100'\n",
    "df.at[1165,'Accession #'] = '1999.10'\n",
    "#2017.14 fixes \n",
    "df.at[462,'Accession #'] = '2017.140'\n",
    "df.at[984,'Accession #'] = '2017.1400'\n",
    "#2002.900 fixes \n",
    "df.at[900,'Accession #'] = '2002.9'\n",
    "df.at[901,'Accession #'] = '2002.10'\n",
    "df.at[904,'Accession #'] = '2002.90'\n",
    "#2019.3 fixes\n",
    "df.at[428,'Accession #'] = '2019.3'\n",
    "df.at[841,'Accession #'] = '2019.30'\n",
    "#2015.300 fixes \n",
    "df.at[316,'Accession #'] = '2015.30'\n",
    "df.at[317,'Accession #'] = '2015.3'\n",
    "#2016.150 fixes \n",
    "df.at[345,'Accession #'] = '2016.15'\n",
    "df.at[806,'Accession #'] = '2016.150'\n",
    "#2017.106 fixes \n",
    "df.at[450,'Accession #'] = '2017.106'\n",
    "df.at[1042,'Accession #'] = '2017.1060'\n",
    "#2016.4 fixes \n",
    "df.at[325,'Accession #'] = '2016.4'\n",
    "df.at[354,'Accession #'] = '2016.40'\n",
    "#2016.5 fixes\n",
    "df.at[326,'Accession #'] = '2016.5'\n",
    "df.at[826,'Accession #'] = '2016.50'\n",
    "#2016.9 fixes\n",
    "df.at[281,'Accession #'] = '2016.90'\n",
    "df.at[331,'Accession #'] = '2016.9'\n",
    "#2018.15 fixes \n",
    "df.at[391,'Accession #'] = '2018.150'\n",
    "df.at[429,'Accession #'] = '2018.15'\n",
    "#2017.3 fixes \n",
    "df.at[277,'Accession #'] = '2017.30'\n",
    "df.at[807,'Accession #'] = '2017.3'\n",
    "#other fixes\n",
    "df.at[398,''] = '2018.160'\n",
    "#Title fixes\n",
    "df.at[879,'Title'] = '\"' + 'And He Smote Job with sore Boils...,' + '\"' + ' plate 6 from the Illustrations of the Book of Job'\n",
    "df.at[878,'Title'] = '\"' + 'I have heard thee with the hearing of the Ear but now my Eye seeth thee,' + '\"' + ' plate 17 from the Illustrations of The Book of Job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to see what was doubled and needing fixing \n",
    "# df_fix = df['Accession #'].value_counts() \n",
    "# df_fix = df_fix[df_fix > 1]\n",
    "# df_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grabbed values needing to be fixed\n",
    "# df_temp = df[df['Accession #'] == 'G1966.2.154']\n",
    "# df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving fixed values to document \n",
    "writer = pd.ExcelWriter('blanton_list_fixed.xlsx', engine='xlsxwriter', \n",
    "                        options = {'string_to_numbers' : False})\n",
    "df.to_excel(writer)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Find which ones have images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "image found at row 7!\n",
      "image found at row 8!\n",
      "image found at row 9!\n",
      "image found at row 10!\n",
      "image found at row 11!\n",
      "image found at row 12!\n",
      "image found at row 13!\n",
      "image found at row 14!\n",
      "image found at row 15!\n",
      "image found at row 16!\n",
      "image found at row 17!\n",
      "image found at row 18!\n",
      "image found at row 19!\n",
      "image found at row 20!\n",
      "image found at row 21!\n",
      "image found at row 22!\n",
      "image found at row 23!\n",
      "image found at row 24!\n",
      "image found at row 25!\n",
      "image found at row 26!\n",
      "image found at row 27!\n",
      "image found at row 28!\n",
      "image found at row 29!\n",
      "image found at row 30!\n",
      "image found at row 31!\n",
      "image found at row 32!\n",
      "image found at row 33!\n",
      "image found at row 34!\n",
      "image found at row 35!\n",
      "image found at row 36!\n",
      "image found at row 37!\n",
      "38\n",
      "image found at row 39!\n",
      "image found at row 40!\n",
      "image found at row 41!\n",
      "image found at row 42!\n",
      "image found at row 43!\n",
      "image found at row 44!\n",
      "image found at row 45!\n",
      "image found at row 46!\n",
      "image found at row 47!\n",
      "image found at row 48!\n",
      "image found at row 49!\n",
      "image found at row 50!\n",
      "image found at row 51!\n"
     ]
    }
   ],
   "source": [
    "for row, data in df.iterrows():\n",
    "    if row == 1372:\n",
    "        break\n",
    "    #create url\n",
    "    title = df.iloc[row]['Title']\n",
    "    name = df.iloc[row]['Artist sort name']\n",
    "    accession = df.iloc[row]['Accession #']\n",
    "        \n",
    "    url = f\"https://collection.blantonmuseum.org/objects-1/info?query=mfs all \\\"{accession} {title} {name}\\\"&sort=9\"\n",
    "    #get JSON data and get rid of any trailing \n",
    "    response  = requests.get(url)\n",
    "    text = response.text\n",
    "\n",
    "    current_has_image = text.find(\"This object does not have an image\") == -1\n",
    "    \n",
    "    df.at[row,'has_image'] = False\n",
    "    if current_has_image:\n",
    "        print(\"image found at row \" + str(row) + \"!\")\n",
    "        df.at[row, 'has_image'] = True\n",
    "    else:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = df[df['has_image'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving fixed values to document \n",
    "writer = pd.ExcelWriter('blanton_list_images.xlsx', engine='xlsxwriter', \n",
    "                        options = {'string_to_numbers' : False})\n",
    "df_images.to_excel(writer)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare sizes of old and new dataframe\n",
    "df_rows = len(df.axes[0])\n",
    "df_images_rows = len(df_images.axes[0])\n",
    "diff = (df_images_rows / df_rows) * 100\n",
    "\n",
    "print(str(diff) + \"% of rows have images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
